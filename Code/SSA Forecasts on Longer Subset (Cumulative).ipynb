{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1VdWjpACvWMm4Zu8LS9IsGWu7oCYTylZl","timestamp":1754055213888}],"authorship_tag":"ABX9TyNxK1m/yobf5nu/msaodNYT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Importing Libraries and Data**"],"metadata":{"id":"deSNmQtSaeXq"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"1u4adROxacHc","executionInfo":{"status":"ok","timestamp":1754659122148,"user_tz":-60,"elapsed":9276,"user":{"displayName":"Matt Newman","userId":"06253307758744063095"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"788424f9-743a-4e64-eeec-4a41572b6297"},"outputs":[{"output_type":"stream","name":"stdout","text":["                                                          sum\n","AccountId                            TransactionDate         \n","0003a5ae-0c77-4372-b44d-882ef9874a28 2019-05-01      -5541.31\n","                                     2019-06-01      -3601.46\n","                                     2019-07-01       3151.74\n","                                     2019-08-01      -4801.13\n","                                     2019-09-01       3890.05\n","...                                                       ...\n","fff7f00c-c869-4310-b705-4503538f5ecf 2020-03-01       2974.84\n","                                     2020-04-01        382.93\n","                                     2020-05-01        166.15\n","                                     2020-06-01       -550.89\n","                                     2020-07-01      -2721.18\n","\n","[7632 rows x 1 columns]\n","                                                            sum\n","AccountId                            TransactionDate           \n","2846c3f5-08a2-4683-b9e5-cf800a931ddc 2019-05-01       -77083.54\n","                                     2019-06-01      -140351.80\n","                                     2019-07-01      -228771.93\n","                                     2019-08-01      -121722.39\n","                                     2019-09-01      -189026.75\n","...                                                         ...\n","b17e0efb-7e15-4baa-8a85-3d2410d1db0a 2020-03-01       -45201.12\n","                                     2020-04-01       -41990.00\n","                                     2020-05-01       -74717.32\n","                                     2020-06-01       -64077.39\n","                                     2020-07-01       -89374.71\n","\n","[7758 rows x 1 columns]\n","                                 AccountId TransactionDate         sum\n","0     2846c3f5-08a2-4683-b9e5-cf800a931ddc      2019-05-01   -77083.54\n","1     2846c3f5-08a2-4683-b9e5-cf800a931ddc      2019-06-01  -217435.34\n","2     2846c3f5-08a2-4683-b9e5-cf800a931ddc      2019-07-01  -446207.27\n","3     2846c3f5-08a2-4683-b9e5-cf800a931ddc      2019-08-01  -567929.66\n","4     2846c3f5-08a2-4683-b9e5-cf800a931ddc      2019-09-01  -756956.41\n","...                                    ...             ...         ...\n","7753  b17e0efb-7e15-4baa-8a85-3d2410d1db0a      2020-03-01  -776644.42\n","7754  b17e0efb-7e15-4baa-8a85-3d2410d1db0a      2020-04-01  -818634.42\n","7755  b17e0efb-7e15-4baa-8a85-3d2410d1db0a      2020-05-01  -893351.74\n","7756  b17e0efb-7e15-4baa-8a85-3d2410d1db0a      2020-06-01  -957429.13\n","7757  b17e0efb-7e15-4baa-8a85-3d2410d1db0a      2020-07-01 -1046803.84\n","\n","[7758 rows x 3 columns]\n"]}],"source":["#Importing libraries\n","import pandas as pd\n","import statsmodels.api as sm\n","from sklearn.metrics import root_mean_squared_error\n","from statsmodels.tsa.stattools import acf\n","import matplotlib.pyplot as plt\n","from mySSA import mySSA\n","import numpy as np\n","import warnings\n","import gc\n","import os\n","import sys\n","\n","#Ignoring warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","#Reading in the data and extracting unique account values\n","BoostedTransactions = pd.read_csv(\"Longer Subset of Transaction Data (14 Months).csv\")\n","AccountIDs = BoostedTransactions[\"AccountId\"].values\n","UniqueAccounts = set(AccountIDs)\n","\n","#Converting transaction dates into months\n","BoostedTransactions[\"TransactionDate\"] = pd.to_datetime(BoostedTransactions[\"TransactionDate\"])\n","BoostedTransactions[\"TransactionDate\"] = BoostedTransactions[\"TransactionDate\"].dt.to_period(\"M\").dt.to_timestamp()\n","\n","#Grouping transactions by account and month and summating each grouping's net transaction amount\n","GroupedSumOfTransactionsByAccountAndMonth = BoostedTransactions.groupby(by=[\"AccountId\", \"TransactionDate\"]).agg([\"sum\"])[\"Amount\"]\n","print(GroupedSumOfTransactionsByAccountAndMonth)\n","\n","#Creating a list to store each account's time series in\n","DataFrames = []\n","\n","#Imputing 0 values into the gaps in each account's time series\n","for i in range(0, len(UniqueAccounts)):\n","  ResetDataFrame = GroupedSumOfTransactionsByAccountAndMonth.reset_index()\n","  TimeSeries = ResetDataFrame[ResetDataFrame[\"AccountId\"] == list(UniqueAccounts)[i]]\n","  TimeSeries = TimeSeries.set_index(\"TransactionDate\")\n","\n","  TimeSeries = TimeSeries.resample(\"MS\").sum()\n","  for j in range(0, len(TimeSeries)):\n","    if TimeSeries.iloc[j][\"AccountId\"] == 0:\n","      TimeSeries.at[TimeSeries.index[j], \"AccountId\"] = list(UniqueAccounts)[i]\n","\n","  DataFrames.append(TimeSeries)\n","\n","#Combining all accounts' time series into a new grouped dataset\n","NewGroupedDataset = pd.concat(DataFrames)\n","NewGroupedDataset = NewGroupedDataset.reset_index()\n","NewGroupedDataset = NewGroupedDataset.set_index([\"AccountId\", \"TransactionDate\"])\n","print(NewGroupedDataset)\n","\n","#Calculating the cumulative transaction sum over the time period for each account\n","GroupedCumulativeSumOfTransactionsByAccountAndMonth = NewGroupedDataset.groupby(level=0).cumsum().reset_index()\n","print(GroupedCumulativeSumOfTransactionsByAccountAndMonth)"]},{"cell_type":"markdown","source":["**Key SSA Loop**\n","\n","This will only execute if the mySSA.py Python class is imported into the Colab environment."],"metadata":{"id":"hKVAUc5Qahst"}},{"cell_type":"code","source":["#Creating models and forecasting for all accounts\n","for i in UniqueAccounts:\n","    print(i)\n","    try:\n","        #Selecting only the current account's time series\n","        ForecastingTestTimeSeries = GroupedCumulativeSumOfTransactionsByAccountAndMonth[GroupedCumulativeSumOfTransactionsByAccountAndMonth[\"AccountId\"] == i][[\"TransactionDate\", \"sum\"]]\n","\n","        ForecastingTestTimeSeries = ForecastingTestTimeSeries.set_index(\"TransactionDate\")\n","\n","        #Calculating the cutoff point between training and testing sets\n","        TrainEnd = int(0.7 * len(ForecastingTestTimeSeries))\n","\n","        #Splitting the dataset into training and testing sets\n","        TrainData = ForecastingTestTimeSeries[:TrainEnd]\n","        TestData = ForecastingTestTimeSeries[TrainEnd:]\n","\n","        #Setting the window length L to N/2 unless N/2 is less than 2\n","        if len(TrainData) <= 2:\n","            L = len(TrainData)\n","        else:\n","            L = max(2, len(TrainData) // 2)\n","\n","        #Calculating K based on L and selecting the suspected frequency based on significant autocorrelations\n","        #It is set as 0 if none are detected\n","        K = len(TrainData) - L + 1\n","        try:\n","            if K <= 1:\n","              MostSignificantLag = 0\n","            else:\n","              ACFValues = acf(TrainData.iloc[:, 0], nlags=K, fft=False)\n","              MostSignificantLag = ACFValues[1:].argmax() + 1\n","              Threshold = 0.2\n","              if np.isnan(ACFValues).any():\n","                  MostSignificantLag = 0\n","              else:\n","                  MostSignificantLag = ACFValues[1:].argmax() + 1\n","                  Threshold = 0.2\n","                  if ACFValues[MostSignificantLag] < Threshold:\n","                      MostSignificantLag = 0\n","        except Exception as e:\n","            MostSignificantLag = 0\n","\n","        #Training an SSA model, embedding and decomposing\n","        if TrainData.empty or TrainData.isnull().all().any():\n","            print(f\"Skipping account {i} due to empty or invalid TrainData\")\n","            #print(TrainData)\n","            break\n","        SSA = mySSA(TrainData)\n","\n","        SSA.embed(embedding_dimension=K, suspected_frequency=MostSignificantLag)\n","\n","        SSA.decompose()\n","\n","        #Analysing signal contributions\n","        Contributions = SSA.view_s_contributions(adjust_scale=True, return_df=True)\n","\n","        #Creating lists to store stream numbers and error statistics\n","        StreamNumbers = []\n","        ErrorsRMSE = []\n","        ErrorsSI = []\n","\n","        #Trying all potential stream numbers to see which one returns the lowest RMSE\n","        for h in range(1, (len(Contributions)+1)):\n","            Streams = [j for j in range(h)]\n","            if hasattr(SSA, 'X_com_hat'):\n","                del SSA.X_com_hat\n","            Forecast = SSA.forecast_recurrent(steps_ahead=(len(ForecastingTestTimeSeries)-TrainEnd), singular_values=Streams, return_df=True)\n","            Forecast[\"Forecast\"] = Forecast[\"Forecast\"].clip(lower=-1e6, upper=1e6)\n","            Forecast[\"Forecast\"] = Forecast[\"Forecast\"].fillna(0)\n","            try:\n","                RMSE = root_mean_squared_error(TestData[\"sum\"], Forecast[\"Forecast\"][TrainEnd:])\n","                StreamNumbers.append(h)\n","                ErrorsRMSE.append(RMSE)\n","                ErrorsSI.append(abs(RMSE/abs(TestData[\"sum\"]).mean()))\n","            except ValueError as eV:\n","                print(\"Bad RMSE value encountered.\")\n","                print(TestData[\"sum\"])\n","                print(Forecast[\"Forecast\"])\n","                print(RMSE)\n","                print(abs(RMSE/abs(TestData[\"sum\"]).mean()))\n","                ErrorType, ErrorObject, ErrorTraceback = sys.exc_info()\n","\n","                ErrorFilename = os.path.split(\n","                    ErrorTraceback.tb_frame.f_code.co_filename\n","                )[1]\n","\n","                ErrorMessage = str(eV)\n","\n","                ErrorLineNumber = ErrorTraceback.tb_lineno\n","\n","                print(f'Exception Type: {ErrorType}')\n","\n","                print(f'Exception Filename: {ErrorFilename}')\n","\n","                print(f'Exception Line Number: {ErrorLineNumber}')\n","\n","                print(f'Exception Message: {ErrorMessage}')\n","                break\n","\n","        ErrorData = pd.DataFrame({\"Streams\" : StreamNumbers,\n","                         \"RMSE\" : ErrorsRMSE,\n","                         \"SI\" : ErrorsSI})\n","        #Taking the stream number with the lowest RMSE and appending its error statistics into the errors CSV\n","        try:\n","          IdealNumberOfStreams = ErrorData.loc[ErrorData[\"RMSE\"].idxmin()][\"Streams\"]\n","          #print(IdealNumberOfStreams)\n","          LowestRMSE = ErrorData.loc[ErrorData[\"RMSE\"].idxmin()][\"RMSE\"]\n","          LowestSI = ErrorData.loc[ErrorData[\"SI\"].idxmin()][\"SI\"]\n","          AccountError = pd.DataFrame({\"AccountID\" : [i],\n","                                        \"RMSE\" : [LowestRMSE],\n","                                        \"SI\" : [LowestSI]})\n","          AccountError.to_csv(\"SSA Longer Subset Errors (Cumulative).csv\", mode='a', header=not os.path.exists(\"SSA Longer Subset Errors (Cumulative).csv\"), index=False)\n","        except ValueError:\n","          print(\"ValueError encountered\")\n","          print(ErrorData)\n","          break\n","\n","        #Forecasting the next 12 months using the chosen forecast\n","        IdealStreams = [k for k in range(int(IdealNumberOfStreams))]\n","\n","        if hasattr(SSA, 'X_com_hat'):\n","            del SSA.X_com_hat\n","\n","        BestForecast = SSA.forecast_recurrent(steps_ahead=((len(ForecastingTestTimeSeries)-TrainEnd)+12), singular_values=IdealStreams, return_df=True)\n","\n","        FutureForecast = BestForecast[-12:][\"Forecast\"].values\n","\n","        #Calculating starting amount, ending amount and net change and appending them into the forecasts CSV file\n","        NetChange = FutureForecast[-1] - FutureForecast[0]\n","        StartingAmount = FutureForecast[0]\n","        EndingAmount = FutureForecast[-1]\n","\n","        ForecastData = pd.DataFrame({\"AccountID\" : [i],\n","                                     \"Net Change over Forecast Period\" : [NetChange],\n","                                     \"Starting Amount\" : [StartingAmount],\n","                                     \"Ending Amount\" : [EndingAmount]})\n","\n","        ForecastData.to_csv(\"SSA Longer Subset Forecasts (Cumulative).csv\", mode='a', header=not os.path.exists(\"SSA Longer Subset Forecasts (Cumulative).csv\"), index=False)\n","\n","        print(\"Processed account number\",i)\n","    #Where an error is returned, the user is informed about it\n","    except Exception as e:\n","        print(f\"Error encountered processing account number {i}.\")\n","        ErrorType, ErrorObject, ErrorTraceback = sys.exc_info()\n","\n","        ErrorFilename = os.path.split(\n","            ErrorTraceback.tb_frame.f_code.co_filename\n","        )[1]\n","\n","        ErrorMessage = str(e)\n","\n","        ErrorLineNumber = ErrorTraceback.tb_lineno\n","\n","        print(f'Exception Type: {ErrorType}')\n","\n","        print(f'Exception Filename: {ErrorFilename}')\n","\n","        print(f'Exception Line Number: {ErrorLineNumber}')\n","\n","        print(f'Exception Message: {ErrorMessage}')\n","        break\n","    #Deleting model data to conserve RAM\n","    finally:\n","        del SSA, Forecast, TrainData, TestData, ForecastingTestTimeSeries\n","        gc.collect()\n","\n","print(\"Code executed successfully.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1clYsj9c-eZTLPLWvE83i_0X9zGPCatsZ"},"id":"23eODNdOa6xz","executionInfo":{"status":"ok","timestamp":1754659437256,"user_tz":-60,"elapsed":21950,"user":{"displayName":"Matt Newman","userId":"06253307758744063095"}},"outputId":"5df32e1c-a7b7-4e95-82f9-14c462e34c5f"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["#Calculating averaged error statistics\n","Errors = pd.read_csv(\"SSA Errors.csv\")\n","MeanRMSE = Errors[\"RMSE\"].mean()\n","print(\"Mean RMSE:\",MeanRMSE)\n","MedianRMSE = Errors[\"RMSE\"].median()\n","print(\"Median RMSE:\",MedianRMSE)\n","MeanSI = Errors[\"SI\"].mean()\n","print(\"Mean SI:\",MeanSI)\n","MedianSI = Errors[\"SI\"].median()\n","print(\"Median SI:\",MedianSI)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oYEHAU6te4Zv","executionInfo":{"status":"ok","timestamp":1754659627334,"user_tz":-60,"elapsed":42,"user":{"displayName":"Matt Newman","userId":"06253307758744063095"}},"outputId":"406bb0ce-f188-4695-f304-f539a067d217"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mean RMSE: 525789.3850472847\n","Median RMSE: 23368.34271150353\n","Mean SI: 0.7174521918825119\n","Median SI: 0.5657585588450607\n"]}]}]}