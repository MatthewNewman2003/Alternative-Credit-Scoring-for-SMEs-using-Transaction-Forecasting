{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOh4ofpPVlKC4VnxiVUQsNo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Importing Libraries and Data**"],"metadata":{"id":"deSNmQtSaeXq"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"1u4adROxacHc","executionInfo":{"status":"ok","timestamp":1754563122024,"user_tz":-60,"elapsed":9521,"user":{"displayName":"Matt Newman","userId":"06253307758744063095"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ccefe43e-82d3-4841-a2f9-f55b370cc43e"},"outputs":[{"output_type":"stream","name":"stdout","text":["                                                          sum\n","AccountId                            TransactionDate         \n","0003a5ae-0c77-4372-b44d-882ef9874a28 2019-05-01      -5541.31\n","                                     2019-06-01      -3601.46\n","                                     2019-07-01       3151.74\n","                                     2019-08-01      -4801.13\n","                                     2019-09-01       3890.05\n","...                                                       ...\n","fff7f00c-c869-4310-b705-4503538f5ecf 2020-03-01       2974.84\n","                                     2020-04-01        382.93\n","                                     2020-05-01        166.15\n","                                     2020-06-01       -550.89\n","                                     2020-07-01      -2721.18\n","\n","[10995 rows x 1 columns]\n","                                                            sum\n","AccountId                            TransactionDate           \n","291e9077-7c91-430a-936d-2faf0876f8fe 2019-05-01      -396233.64\n","                                     2019-06-01      -572848.74\n","                                     2019-07-01      -919407.80\n","                                     2019-08-01      -801557.35\n","                                     2019-09-01      -734492.01\n","...                                                         ...\n","deb56545-2fd1-4202-8de7-19d6176c2334 2019-08-01         2835.74\n","                                     2019-09-01            0.00\n","                                     2019-10-01        -5723.06\n","                                     2019-11-01         -549.45\n","                                     2019-12-01        -2826.77\n","\n","[12545 rows x 1 columns]\n","                                  AccountId TransactionDate         sum\n","0      291e9077-7c91-430a-936d-2faf0876f8fe      2019-05-01  -396233.64\n","1      291e9077-7c91-430a-936d-2faf0876f8fe      2019-06-01  -969082.38\n","2      291e9077-7c91-430a-936d-2faf0876f8fe      2019-07-01 -1888490.18\n","3      291e9077-7c91-430a-936d-2faf0876f8fe      2019-08-01 -2690047.53\n","4      291e9077-7c91-430a-936d-2faf0876f8fe      2019-09-01 -3424539.54\n","...                                     ...             ...         ...\n","12540  deb56545-2fd1-4202-8de7-19d6176c2334      2019-08-01     2092.98\n","12541  deb56545-2fd1-4202-8de7-19d6176c2334      2019-09-01     2092.98\n","12542  deb56545-2fd1-4202-8de7-19d6176c2334      2019-10-01    -3630.08\n","12543  deb56545-2fd1-4202-8de7-19d6176c2334      2019-11-01    -4179.53\n","12544  deb56545-2fd1-4202-8de7-19d6176c2334      2019-12-01    -7006.30\n","\n","[12545 rows x 3 columns]\n"]}],"source":["#Importing libraries\n","import pandas as pd\n","import statsmodels.api as sm\n","from sklearn.metrics import root_mean_squared_error\n","from statsmodels.tsa.stattools import acf\n","import matplotlib.pyplot as plt\n","from mySSA import mySSA\n","import numpy as np\n","import warnings\n","import gc\n","import os\n","import sys\n","\n","#Ignoring warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","#Reading in the data and extracting unique account values\n","BoostedTransactions = pd.read_csv(\"Boosted Transaction Dataset.csv\")\n","AccountIDs = BoostedTransactions[\"AccountId\"].values\n","UniqueAccounts = set(AccountIDs)\n","\n","#Converting transaction dates to months\n","BoostedTransactions[\"TransactionDate\"] = pd.to_datetime(BoostedTransactions[\"TransactionDate\"])\n","BoostedTransactions[\"TransactionDate\"] = BoostedTransactions[\"TransactionDate\"].dt.to_period(\"M\").dt.to_timestamp()\n","\n","#Grouping transactions by account and month and summating each grouping's net transaction amount\n","GroupedSumOfTransactionsByAccountAndMonth = BoostedTransactions.groupby(by=[\"AccountId\", \"TransactionDate\"]).agg([\"sum\"])[\"Amount\"]\n","print(GroupedSumOfTransactionsByAccountAndMonth)\n","\n","#Creating a list to store all accounts' time series in\n","DataFrames = []\n","\n","#Imputing 0 values into the gaps in each account's time series\n","for i in range(0, len(UniqueAccounts)):\n","  ResetDataFrame = GroupedSumOfTransactionsByAccountAndMonth.reset_index()\n","  TimeSeries = ResetDataFrame[ResetDataFrame[\"AccountId\"] == list(UniqueAccounts)[i]]\n","  TimeSeries = TimeSeries.set_index(\"TransactionDate\")\n","\n","  TimeSeries = TimeSeries.resample(\"MS\").sum()\n","  for j in range(0, len(TimeSeries)):\n","    if TimeSeries.iloc[j][\"AccountId\"] == 0:\n","      TimeSeries.at[TimeSeries.index[j], \"AccountId\"] = list(UniqueAccounts)[i]\n","\n","  DataFrames.append(TimeSeries)\n","\n","#Combining all accounts' time series into a new grouped dataset\n","NewGroupedDataset = pd.concat(DataFrames)\n","NewGroupedDataset = NewGroupedDataset.reset_index()\n","NewGroupedDataset = NewGroupedDataset.set_index([\"AccountId\", \"TransactionDate\"])\n","print(NewGroupedDataset)\n","\n","#Calculating the cumulative transaction sum over the time period for each account\n","GroupedCumulativeSumOfTransactionsByAccountAndMonth = NewGroupedDataset.groupby(level=0).cumsum().reset_index()\n","print(GroupedCumulativeSumOfTransactionsByAccountAndMonth)"]},{"cell_type":"markdown","source":["**Key SSA Loop**\n","\n","This cannot be executed without the mySSA.py Python class in the Colab environment, which can be found in the code folder."],"metadata":{"id":"hKVAUc5Qahst"}},{"cell_type":"code","source":["#Creating models and forecasting for all accounts\n","for i in UniqueAccounts:\n","    print(i)\n","    try:\n","        #Selecting only the current account's time series\n","        ForecastingTestTimeSeries = GroupedCumulativeSumOfTransactionsByAccountAndMonth[GroupedCumulativeSumOfTransactionsByAccountAndMonth[\"AccountId\"] == i][[\"TransactionDate\", \"sum\"]]\n","\n","        ForecastingTestTimeSeries = ForecastingTestTimeSeries.set_index(\"TransactionDate\")\n","\n","        #Calculating the cutoff point between training and testing sets\n","        TrainEnd = int(0.7 * len(ForecastingTestTimeSeries))\n","\n","        #Splitting the data into training and testing sets\n","        TrainData = ForecastingTestTimeSeries[:TrainEnd]\n","        TestData = ForecastingTestTimeSeries[TrainEnd:]\n","\n","        #Assigning a window length L based on training data length, with L/2 being assigned unless L/2 is less than 2\n","        if len(TrainData) <= 2:\n","            L = len(TrainData)\n","        else:\n","            L = max(2, len(TrainData) // 2)\n","\n","        #Calculating K and assigning the most significant lag based on significant autocorrelations, with 0 being assigned if none exist\n","        K = len(TrainData) - L + 1\n","        try:\n","            if K <= 1:\n","              MostSignificantLag = 0\n","            else:\n","              ACFValues = acf(TrainData.iloc[:, 0], nlags=K, fft=False)\n","              MostSignificantLag = ACFValues[1:].argmax() + 1\n","              Threshold = 0.2\n","              if np.isnan(ACFValues).any():\n","                  MostSignificantLag = 0\n","              else:\n","                  MostSignificantLag = ACFValues[1:].argmax() + 1\n","                  Threshold = 0.2\n","                  if ACFValues[MostSignificantLag] < Threshold:\n","                      MostSignificantLag = 0\n","        except Exception as e:\n","            MostSignificantLag = 0\n","\n","        #Creating the SSA model, embedding and decomposing\n","        if TrainData.empty or TrainData.isnull().all().any():\n","            print(f\"Skipping account {i} due to empty or invalid TrainData\")\n","            #print(TrainData)\n","            break\n","        SSA = mySSA(TrainData)\n","\n","        SSA.embed(embedding_dimension=K, suspected_frequency=MostSignificantLag)\n","\n","        SSA.decompose()\n","\n","        #Getting contributing signals\n","        Contributions = SSA.view_s_contributions(adjust_scale=True, return_df=True)\n","\n","        #Creating lists to store stream numbers and their RMSEs and SIs\n","        StreamNumbers = []\n","        ErrorsRMSE = []\n","        ErrorsSI = []\n","\n","        #Testing each number of streams from the contributions to see which one returns the lowest RMSE\n","        for h in range(1, (len(Contributions)+1)):\n","            Streams = [j for j in range(h)]\n","            if hasattr(SSA, 'X_com_hat'):\n","                del SSA.X_com_hat\n","            Forecast = SSA.forecast_recurrent(steps_ahead=(len(ForecastingTestTimeSeries)-TrainEnd), singular_values=Streams, return_df=True)\n","            Forecast[\"Forecast\"] = Forecast[\"Forecast\"].clip(lower=-1e6, upper=1e6)\n","            Forecast[\"Forecast\"] = Forecast[\"Forecast\"].fillna(0)\n","            try:\n","                RMSE = root_mean_squared_error(TestData[\"sum\"], Forecast[\"Forecast\"][TrainEnd:])\n","                StreamNumbers.append(h)\n","                ErrorsRMSE.append(RMSE)\n","                ErrorsSI.append(abs(RMSE/abs(TestData[\"sum\"]).mean()))\n","            except ValueError as eV:\n","                print(\"Bad RMSE value encountered.\")\n","                print(TestData[\"sum\"])\n","                print(Forecast[\"Forecast\"])\n","                print(RMSE)\n","                print(abs(RMSE/abs(TestData[\"sum\"]).mean()))\n","                ErrorType, ErrorObject, ErrorTraceback = sys.exc_info()\n","\n","                ErrorFilename = os.path.split(\n","                    ErrorTraceback.tb_frame.f_code.co_filename\n","                )[1]\n","\n","                ErrorMessage = str(eV)\n","\n","                ErrorLineNumber = ErrorTraceback.tb_lineno\n","\n","                print(f'Exception Type: {ErrorType}')\n","\n","                print(f'Exception Filename: {ErrorFilename}')\n","\n","                print(f'Exception Line Number: {ErrorLineNumber}')\n","\n","                print(f'Exception Message: {ErrorMessage}')\n","                break\n","\n","        ErrorData = pd.DataFrame({\"Streams\" : StreamNumbers,\n","                         \"RMSE\" : ErrorsRMSE,\n","                         \"SI\" : ErrorsSI})\n","        #Taking the number of streams with the lowest RMSE and appending its error rates into the errors CSV file\n","        try:\n","          IdealNumberOfStreams = ErrorData.loc[ErrorData[\"RMSE\"].idxmin()][\"Streams\"]\n","          LowestRMSE = ErrorData.loc[ErrorData[\"RMSE\"].idxmin()][\"RMSE\"]\n","          LowestSI = ErrorData.loc[ErrorData[\"SI\"].idxmin()][\"SI\"]\n","          AccountError = pd.DataFrame({\"AccountID\" : [i],\n","                                        \"RMSE\" : [LowestRMSE],\n","                                        \"SI\" : [LowestSI]})\n","          AccountError.to_csv(\"SSA Errors (Cumulative).csv\", mode='a', header=not os.path.exists(\"SSA Errors (Cumulative).csv\"), index=False)\n","        except ValueError:\n","          print(\"ValueError encountered\")\n","          print(ErrorData)\n","          break\n","\n","        #Taking the ideal streams and performing a 12-month forecast based on them\n","        IdealStreams = [k for k in range(int(IdealNumberOfStreams))]\n","\n","        if hasattr(SSA, 'X_com_hat'):\n","            del SSA.X_com_hat\n","\n","        BestForecast = SSA.forecast_recurrent(steps_ahead=((len(ForecastingTestTimeSeries)-TrainEnd)+12), singular_values=IdealStreams, return_df=True)\n","        #print(BestForecast)\n","\n","        FutureForecast = BestForecast[-12:][\"Forecast\"].values\n","        #print(FutureForecast)\n","\n","        #Calculating starting amount, ending amount and net change and appending them into the forecasts CSV file\n","        NetChange = FutureForecast[-1] - FutureForecast[0]\n","        StartingAmount = FutureForecast[0]\n","        EndingAmount = FutureForecast[-1]\n","\n","        ForecastData = pd.DataFrame({\"AccountID\" : [i],\n","                                     \"Net Change over Forecast Period\" : [NetChange],\n","                                     \"Starting Amount\" : [StartingAmount],\n","                                     \"Ending Amount\" : [EndingAmount]})\n","\n","        ForecastData.to_csv(\"SSA Forecasts (Cumulative).csv\", mode='a', header=not os.path.exists(\"SSA Forecasts (Cumulative).csv\"), index=False)\n","\n","        print(\"Processed account number\",i)\n","    #Where an error occurs, the user is informed about it\n","    except Exception as e:\n","        print(f\"Error encountered processing account number {i}.\")\n","        ErrorType, ErrorObject, ErrorTraceback = sys.exc_info()\n","\n","        ErrorFilename = os.path.split(\n","            ErrorTraceback.tb_frame.f_code.co_filename\n","        )[1]\n","\n","        ErrorMessage = str(e)\n","\n","        ErrorLineNumber = ErrorTraceback.tb_lineno\n","\n","        print(f'Exception Type: {ErrorType}')\n","\n","        print(f'Exception Filename: {ErrorFilename}')\n","\n","        print(f'Exception Line Number: {ErrorLineNumber}')\n","\n","        print(f'Exception Message: {ErrorMessage}')\n","        break\n","    #Deleting model data to conserve RAM\n","    finally:\n","        del SSA, Forecast, TrainData, TestData, ForecastingTestTimeSeries\n","        gc.collect()\n","\n","print(\"Code executed successfully.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1K9v5B2m5WWAFA_sDi56RaKRQu78DukBL"},"id":"23eODNdOa6xz","executionInfo":{"status":"ok","timestamp":1754563857976,"user_tz":-60,"elapsed":731780,"user":{"displayName":"Matt Newman","userId":"06253307758744063095"}},"outputId":"0c7ea397-f2c6-469e-994f-7fa0231be77f"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["#Calculating averaged error statistics\n","Errors = pd.read_csv(\"SSA Errors (Cumulative).csv\")\n","MeanRMSE = Errors[\"RMSE\"].mean()\n","print(\"Mean RMSE:\",MeanRMSE)\n","MedianRMSE = Errors[\"RMSE\"].median()\n","print(\"Median RMSE:\",MedianRMSE)\n","MeanSI = Errors[\"SI\"].mean()\n","print(\"Mean SI:\",MeanSI)\n","MedianSI = Errors[\"SI\"].median()\n","print(\"Median SI:\",MedianSI)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oYEHAU6te4Zv","executionInfo":{"status":"ok","timestamp":1754563865675,"user_tz":-60,"elapsed":27,"user":{"displayName":"Matt Newman","userId":"06253307758744063095"}},"outputId":"8bb67913-1bcc-4d86-f239-16e372de2742"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mean RMSE: 317311.17644744704\n","Median RMSE: 10585.65184997053\n","Mean SI: 0.8958266371452679\n","Median SI: 0.6152184939762161\n"]}]}]}